Linear vs Lasso Regression¶
The given dataset contains price of second-hand Hyundai grand i10 car with respect to year of making. Find the best linear relationship between year and price. Can you predict the possible price of a 2022 model second-hand grand i10? Please learn about lasso regression and create a model along with linear regression. Find out which one is performing better.

In [1]:#importing the required libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

In [33]:#loading the data and reading the file

df=pd.read_csv("car_age_price.csv")
df.tail()

Out[33]: Year Price 
107 2016 375000 
108 2014 300000 
109 2015 425000 
110 2016 420000 
111 2015 425000 

In [3]:df.describe()

Out[3]: Year Price 
count 112.000000 112.000000 
mean 2016.669643 483866.044643 
std 1.629616 91217.450533 
min 2013.000000 300000.000000 
25% 2015.000000 423750.000000 
50% 2017.000000 500000.000000 
75% 2017.000000 550000.000000 
max 2020.000000 755000.000000 

Finding Correlation and Plotting it Using a Heatmap

In [4]:corrmatrix=df.corr()
corrmatrix

Out[4]: Year Price 
Year 1.000000 0.776302 
Price 0.776302 1.000000 

In [35]:plt.subplots(figsize=(10,4))
sns.heatmap(corrmatrix,annot=True,vmin=-0.5,vmax=1,linewidth=0.2,cmap='YlGnBu')

Out[35]:<AxesSubplot:> 
Finding Linear Regression

In [6]:# identify independant(x) and dependant variable(y) and classify the data

y=df['Price']
x=df.drop(['Price'],axis=1)

In [7]:x

Out[7]: Year 
0 2018 
1 2019 
2 2019 
3 2018 
4 2018 
... ... 
107 2016 
108 2014 
109 2015 
110 2016 
111 2015 

112 rows × 1 columns

In [8]:y

Out[8]:0      465000
1      755000
2      700000
3      465000
4      465000
        ...  
107    375000
108    300000
109    425000
110    420000
111    425000
Name: Price, Length: 112, dtype: int64
Plot the Data

In [9]:# Plotting a scatter plot

plt.scatter(x,y)
plt.xlabel('Year',fontsize=15)
plt.ylabel('Price',fontsize=15)
plt.show()

 
In [10]:#as the Year goes on, the price of the cars are also increasing. Therefore we can say that 
#there is a linear relationship between the two variables.

Training and Testing

In [36]:#import the required library  
#split the data for training and testing

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test= train_test_splitx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.3,random_state=42)

In [37]:#creating a model

from sklearn import linear_model
lr=linear_model.LinearRegression()

In [38]:#fitting the model 

model=lr.fit(x_train,y_train)

In [39]:#Finding the coefficients of the model

print("Intercept :",lr.intercept_)
print("Slope :",lr.coef_)

Intercept : -93469862.64714085
Slope : [46591.75732218]

In [40]:#predicting the y values 
y_pred=model.predict(x_test)
y_pred

Out[40]:array([598895.38633195, 505711.87168759, 552303.62900977, 552303.62900977,
       552303.62900977, 412528.35704324, 505711.87168759, 552303.62900977,
       598895.38633195, 598895.38633195, 319344.8423989 , 505711.87168759,
       412528.35704324, 645487.14365412, 552303.62900977, 598895.38633195,
       319344.8423989 , 412528.35704324, 505711.87168759, 505711.87168759,
       505711.87168759, 505711.87168759, 505711.87168759, 505711.87168759,
       505711.87168759, 505711.87168759, 412528.35704324, 412528.35704324,
       365936.59972107, 412528.35704324, 505711.87168759, 598895.38633195,
       552303.62900977, 505711.87168759])
Plot the Training and Testing Data

In [16]:plt.scatter(x_train, y_train, color = "blue")
plt.plot(x_train, model.predict(x_train), color = "red")
plt.title("Training set")
plt.xlabel("Years")
plt.ylabel("Price")
plt.show()

 
In [17]:plt.scatter(x_test, y_test, color = "red")
plt.plot(x_train,model.predict(x_train), color = "green")
plt.title("Testing set")
plt.xlabel("Years")
plt.ylabel("Price")
plt.show()

 
In [18]:#finding the mean squared error for the variables

from sklearn.metrics import mean_squared_error 
print('MSE=',mean_squared_error(y_test,y_pred))

MSE= 3878767151.073449

In [19]:#finding the coefficient of determination, R square.

from sklearn.metrics import r2_score 
print('r2_score=',r2_score(y_test,y_pred))

r2_score= 0.4347961632108023

Lasso Regression

In [20]:import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import Lasso

In [21]:df=pd.read_csv("car_age_price.csv")
df.head()

Out[21]: Year Price 
0 2018 465000 
1 2019 755000 
2 2019 700000 
3 2018 465000 
4 2018 465000 

In [22]:y=df['Price']
x=df.drop(['Price'],axis=1)

In [23]:print(x)
print(y)

     Year
0    2018
1    2019
2    2019
3    2018
4    2018
..    ...
107  2016
108  2014
109  2015
110  2016
111  2015

[112 rows x 1 columns]
0      465000
1      755000
2      700000
3      465000
4      465000
        ...  
107    375000
108    300000
109    425000
110    420000
111    425000
Name: Price, Length: 112, dtype: int64

In [24]:#creating training and testing data
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)

In [25]:## Build the lasso model with alpha

model_lasso = Lasso(alpha=1)
#fit the model
model_lasso.fit(x_train, y_train)

Out[25]:Lasso(alpha=1)
In [26]:#create the model score
model_lasso.score(x_test, y_test), model_lasso.score(x_train, y_train)

Out[26]:(0.5055229997509045, 0.6352750042427691)
In [27]:model_lasso.coef_

Out[27]:array([46830.99440651])
In [28]:from numpy import mean
from numpy import std
from numpy import absolute
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedKFold

cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate model
scores = cross_val_score(model_lasso, x, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)
# force scores to be positive
scores = absolute(scores)
print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))

Mean MAE: 47318.131 (10661.378)

In [ ]:
